Testing command is /home/featurize/work/uc/bin/python /home/featurize/work/uc/lib/python3.9/site-packages/mmseg/.mim/tools/test.py /home/featurize/work/hls-foundation-os/configs/size_5/experiment_2/size_5_experiment_2_fold_1_setting_1.py /home/featurize/Results/Size_5_Experiment_2_Fold_1_Setting_1/best_mIoU_epoch_10.pth --launcher none --eval mFscore. 
load from /home/featurize/work/hls-foundation-os/Current_Pretrained_Prithvi_Weights/Prithvi_EO_V1_100M.pt
load checkpoint from local path: /home/featurize/work/hls-foundation-os/Current_Pretrained_Prithvi_Weights/Prithvi_EO_V1_100M.pt
The model and loaded state dict do not match exactly

unexpected key in source state_dict: encoder.cls_token, encoder.pos_embed, decoder.mask_token, decoder.decoder_pos_embed, encoder.patch_embed.proj.weight, encoder.patch_embed.proj.bias, encoder.blocks.0.norm1.weight, encoder.blocks.0.norm1.bias, encoder.blocks.0.attn.qkv.weight, encoder.blocks.0.attn.qkv.bias, encoder.blocks.0.attn.proj.weight, encoder.blocks.0.attn.proj.bias, encoder.blocks.0.norm2.weight, encoder.blocks.0.norm2.bias, encoder.blocks.0.mlp.fc1.weight, encoder.blocks.0.mlp.fc1.bias, encoder.blocks.0.mlp.fc2.weight, encoder.blocks.0.mlp.fc2.bias, encoder.blocks.1.norm1.weight, encoder.blocks.1.norm1.bias, encoder.blocks.1.attn.qkv.weight, encoder.blocks.1.attn.qkv.bias, encoder.blocks.1.attn.proj.weight, encoder.blocks.1.attn.proj.bias, encoder.blocks.1.norm2.weight, encoder.blocks.1.norm2.bias, encoder.blocks.1.mlp.fc1.weight, encoder.blocks.1.mlp.fc1.bias, encoder.blocks.1.mlp.fc2.weight, encoder.blocks.1.mlp.fc2.bias, encoder.blocks.2.norm1.weight, encoder.blocks.2.norm1.bias, encoder.blocks.2.attn.qkv.weight, encoder.blocks.2.attn.qkv.bias, encoder.blocks.2.attn.proj.weight, encoder.blocks.2.attn.proj.bias, encoder.blocks.2.norm2.weight, encoder.blocks.2.norm2.bias, encoder.blocks.2.mlp.fc1.weight, encoder.blocks.2.mlp.fc1.bias, encoder.blocks.2.mlp.fc2.weight, encoder.blocks.2.mlp.fc2.bias, encoder.blocks.3.norm1.weight, encoder.blocks.3.norm1.bias, encoder.blocks.3.attn.qkv.weight, encoder.blocks.3.attn.qkv.bias, encoder.blocks.3.attn.proj.weight, encoder.blocks.3.attn.proj.bias, encoder.blocks.3.norm2.weight, encoder.blocks.3.norm2.bias, encoder.blocks.3.mlp.fc1.weight, encoder.blocks.3.mlp.fc1.bias, encoder.blocks.3.mlp.fc2.weight, encoder.blocks.3.mlp.fc2.bias, encoder.blocks.4.norm1.weight, encoder.blocks.4.norm1.bias, encoder.blocks.4.attn.qkv.weight, encoder.blocks.4.attn.qkv.bias, encoder.blocks.4.attn.proj.weight, encoder.blocks.4.attn.proj.bias, encoder.blocks.4.norm2.weight, encoder.blocks.4.norm2.bias, encoder.blocks.4.mlp.fc1.weight, encoder.blocks.4.mlp.fc1.bias, encoder.blocks.4.mlp.fc2.weight, encoder.blocks.4.mlp.fc2.bias, encoder.blocks.5.norm1.weight, encoder.blocks.5.norm1.bias, encoder.blocks.5.attn.qkv.weight, encoder.blocks.5.attn.qkv.bias, encoder.blocks.5.attn.proj.weight, encoder.blocks.5.attn.proj.bias, encoder.blocks.5.norm2.weight, encoder.blocks.5.norm2.bias, encoder.blocks.5.mlp.fc1.weight, encoder.blocks.5.mlp.fc1.bias, encoder.blocks.5.mlp.fc2.weight, encoder.blocks.5.mlp.fc2.bias, encoder.blocks.6.norm1.weight, encoder.blocks.6.norm1.bias, encoder.blocks.6.attn.qkv.weight, encoder.blocks.6.attn.qkv.bias, encoder.blocks.6.attn.proj.weight, encoder.blocks.6.attn.proj.bias, encoder.blocks.6.norm2.weight, encoder.blocks.6.norm2.bias, encoder.blocks.6.mlp.fc1.weight, encoder.blocks.6.mlp.fc1.bias, encoder.blocks.6.mlp.fc2.weight, encoder.blocks.6.mlp.fc2.bias, encoder.blocks.7.norm1.weight, encoder.blocks.7.norm1.bias, encoder.blocks.7.attn.qkv.weight, encoder.blocks.7.attn.qkv.bias, encoder.blocks.7.attn.proj.weight, encoder.blocks.7.attn.proj.bias, encoder.blocks.7.norm2.weight, encoder.blocks.7.norm2.bias, encoder.blocks.7.mlp.fc1.weight, encoder.blocks.7.mlp.fc1.bias, encoder.blocks.7.mlp.fc2.weight, encoder.blocks.7.mlp.fc2.bias, encoder.blocks.8.norm1.weight, encoder.blocks.8.norm1.bias, encoder.blocks.8.attn.qkv.weight, encoder.blocks.8.attn.qkv.bias, encoder.blocks.8.attn.proj.weight, encoder.blocks.8.attn.proj.bias, encoder.blocks.8.norm2.weight, encoder.blocks.8.norm2.bias, encoder.blocks.8.mlp.fc1.weight, encoder.blocks.8.mlp.fc1.bias, encoder.blocks.8.mlp.fc2.weight, encoder.blocks.8.mlp.fc2.bias, encoder.blocks.9.norm1.weight, encoder.blocks.9.norm1.bias, encoder.blocks.9.attn.qkv.weight, encoder.blocks.9.attn.qkv.bias, encoder.blocks.9.attn.proj.weight, encoder.blocks.9.attn.proj.bias, encoder.blocks.9.norm2.weight, encoder.blocks.9.norm2.bias, encoder.blocks.9.mlp.fc1.weight, encoder.blocks.9.mlp.fc1.bias, encoder.blocks.9.mlp.fc2.weight, encoder.blocks.9.mlp.fc2.bias, encoder.blocks.10.norm1.weight, encoder.blocks.10.norm1.bias, encoder.blocks.10.attn.qkv.weight, encoder.blocks.10.attn.qkv.bias, encoder.blocks.10.attn.proj.weight, encoder.blocks.10.attn.proj.bias, encoder.blocks.10.norm2.weight, encoder.blocks.10.norm2.bias, encoder.blocks.10.mlp.fc1.weight, encoder.blocks.10.mlp.fc1.bias, encoder.blocks.10.mlp.fc2.weight, encoder.blocks.10.mlp.fc2.bias, encoder.blocks.11.norm1.weight, encoder.blocks.11.norm1.bias, encoder.blocks.11.attn.qkv.weight, encoder.blocks.11.attn.qkv.bias, encoder.blocks.11.attn.proj.weight, encoder.blocks.11.attn.proj.bias, encoder.blocks.11.norm2.weight, encoder.blocks.11.norm2.bias, encoder.blocks.11.mlp.fc1.weight, encoder.blocks.11.mlp.fc1.bias, encoder.blocks.11.mlp.fc2.weight, encoder.blocks.11.mlp.fc2.bias, encoder.norm.weight, encoder.norm.bias, decoder.decoder_embed.weight, decoder.decoder_embed.bias, decoder.decoder_blocks.0.norm1.weight, decoder.decoder_blocks.0.norm1.bias, decoder.decoder_blocks.0.attn.qkv.weight, decoder.decoder_blocks.0.attn.qkv.bias, decoder.decoder_blocks.0.attn.proj.weight, decoder.decoder_blocks.0.attn.proj.bias, decoder.decoder_blocks.0.norm2.weight, decoder.decoder_blocks.0.norm2.bias, decoder.decoder_blocks.0.mlp.fc1.weight, decoder.decoder_blocks.0.mlp.fc1.bias, decoder.decoder_blocks.0.mlp.fc2.weight, decoder.decoder_blocks.0.mlp.fc2.bias, decoder.decoder_blocks.1.norm1.weight, decoder.decoder_blocks.1.norm1.bias, decoder.decoder_blocks.1.attn.qkv.weight, decoder.decoder_blocks.1.attn.qkv.bias, decoder.decoder_blocks.1.attn.proj.weight, decoder.decoder_blocks.1.attn.proj.bias, decoder.decoder_blocks.1.norm2.weight, decoder.decoder_blocks.1.norm2.bias, decoder.decoder_blocks.1.mlp.fc1.weight, decoder.decoder_blocks.1.mlp.fc1.bias, decoder.decoder_blocks.1.mlp.fc2.weight, decoder.decoder_blocks.1.mlp.fc2.bias, decoder.decoder_blocks.2.norm1.weight, decoder.decoder_blocks.2.norm1.bias, decoder.decoder_blocks.2.attn.qkv.weight, decoder.decoder_blocks.2.attn.qkv.bias, decoder.decoder_blocks.2.attn.proj.weight, decoder.decoder_blocks.2.attn.proj.bias, decoder.decoder_blocks.2.norm2.weight, decoder.decoder_blocks.2.norm2.bias, decoder.decoder_blocks.2.mlp.fc1.weight, decoder.decoder_blocks.2.mlp.fc1.bias, decoder.decoder_blocks.2.mlp.fc2.weight, decoder.decoder_blocks.2.mlp.fc2.bias, decoder.decoder_blocks.3.norm1.weight, decoder.decoder_blocks.3.norm1.bias, decoder.decoder_blocks.3.attn.qkv.weight, decoder.decoder_blocks.3.attn.qkv.bias, decoder.decoder_blocks.3.attn.proj.weight, decoder.decoder_blocks.3.attn.proj.bias, decoder.decoder_blocks.3.norm2.weight, decoder.decoder_blocks.3.norm2.bias, decoder.decoder_blocks.3.mlp.fc1.weight, decoder.decoder_blocks.3.mlp.fc1.bias, decoder.decoder_blocks.3.mlp.fc2.weight, decoder.decoder_blocks.3.mlp.fc2.bias, decoder.decoder_blocks.4.norm1.weight, decoder.decoder_blocks.4.norm1.bias, decoder.decoder_blocks.4.attn.qkv.weight, decoder.decoder_blocks.4.attn.qkv.bias, decoder.decoder_blocks.4.attn.proj.weight, decoder.decoder_blocks.4.attn.proj.bias, decoder.decoder_blocks.4.norm2.weight, decoder.decoder_blocks.4.norm2.bias, decoder.decoder_blocks.4.mlp.fc1.weight, decoder.decoder_blocks.4.mlp.fc1.bias, decoder.decoder_blocks.4.mlp.fc2.weight, decoder.decoder_blocks.4.mlp.fc2.bias, decoder.decoder_blocks.5.norm1.weight, decoder.decoder_blocks.5.norm1.bias, decoder.decoder_blocks.5.attn.qkv.weight, decoder.decoder_blocks.5.attn.qkv.bias, decoder.decoder_blocks.5.attn.proj.weight, decoder.decoder_blocks.5.attn.proj.bias, decoder.decoder_blocks.5.norm2.weight, decoder.decoder_blocks.5.norm2.bias, decoder.decoder_blocks.5.mlp.fc1.weight, decoder.decoder_blocks.5.mlp.fc1.bias, decoder.decoder_blocks.5.mlp.fc2.weight, decoder.decoder_blocks.5.mlp.fc2.bias, decoder.decoder_blocks.6.norm1.weight, decoder.decoder_blocks.6.norm1.bias, decoder.decoder_blocks.6.attn.qkv.weight, decoder.decoder_blocks.6.attn.qkv.bias, decoder.decoder_blocks.6.attn.proj.weight, decoder.decoder_blocks.6.attn.proj.bias, decoder.decoder_blocks.6.norm2.weight, decoder.decoder_blocks.6.norm2.bias, decoder.decoder_blocks.6.mlp.fc1.weight, decoder.decoder_blocks.6.mlp.fc1.bias, decoder.decoder_blocks.6.mlp.fc2.weight, decoder.decoder_blocks.6.mlp.fc2.bias, decoder.decoder_blocks.7.norm1.weight, decoder.decoder_blocks.7.norm1.bias, decoder.decoder_blocks.7.attn.qkv.weight, decoder.decoder_blocks.7.attn.qkv.bias, decoder.decoder_blocks.7.attn.proj.weight, decoder.decoder_blocks.7.attn.proj.bias, decoder.decoder_blocks.7.norm2.weight, decoder.decoder_blocks.7.norm2.bias, decoder.decoder_blocks.7.mlp.fc1.weight, decoder.decoder_blocks.7.mlp.fc1.bias, decoder.decoder_blocks.7.mlp.fc2.weight, decoder.decoder_blocks.7.mlp.fc2.bias, decoder.decoder_norm.weight, decoder.decoder_norm.bias, decoder.decoder_pred.weight, decoder.decoder_pred.bias

missing keys in source state_dict: cls_token, pos_embed, patch_embed.proj.weight, patch_embed.proj.bias, blocks.0.norm1.weight, blocks.0.norm1.bias, blocks.0.attn.qkv.weight, blocks.0.attn.qkv.bias, blocks.0.attn.proj.weight, blocks.0.attn.proj.bias, blocks.0.norm2.weight, blocks.0.norm2.bias, blocks.0.mlp.fc1.weight, blocks.0.mlp.fc1.bias, blocks.0.mlp.fc2.weight, blocks.0.mlp.fc2.bias, blocks.1.norm1.weight, blocks.1.norm1.bias, blocks.1.attn.qkv.weight, blocks.1.attn.qkv.bias, blocks.1.attn.proj.weight, blocks.1.attn.proj.bias, blocks.1.norm2.weight, blocks.1.norm2.bias, blocks.1.mlp.fc1.weight, blocks.1.mlp.fc1.bias, blocks.1.mlp.fc2.weight, blocks.1.mlp.fc2.bias, blocks.2.norm1.weight, blocks.2.norm1.bias, blocks.2.attn.qkv.weight, blocks.2.attn.qkv.bias, blocks.2.attn.proj.weight, blocks.2.attn.proj.bias, blocks.2.norm2.weight, blocks.2.norm2.bias, blocks.2.mlp.fc1.weight, blocks.2.mlp.fc1.bias, blocks.2.mlp.fc2.weight, blocks.2.mlp.fc2.bias, blocks.3.norm1.weight, blocks.3.norm1.bias, blocks.3.attn.qkv.weight, blocks.3.attn.qkv.bias, blocks.3.attn.proj.weight, blocks.3.attn.proj.bias, blocks.3.norm2.weight, blocks.3.norm2.bias, blocks.3.mlp.fc1.weight, blocks.3.mlp.fc1.bias, blocks.3.mlp.fc2.weight, blocks.3.mlp.fc2.bias, blocks.4.norm1.weight, blocks.4.norm1.bias, blocks.4.attn.qkv.weight, blocks.4.attn.qkv.bias, blocks.4.attn.proj.weight, blocks.4.attn.proj.bias, blocks.4.norm2.weight, blocks.4.norm2.bias, blocks.4.mlp.fc1.weight, blocks.4.mlp.fc1.bias, blocks.4.mlp.fc2.weight, blocks.4.mlp.fc2.bias, blocks.5.norm1.weight, blocks.5.norm1.bias, blocks.5.attn.qkv.weight, blocks.5.attn.qkv.bias, blocks.5.attn.proj.weight, blocks.5.attn.proj.bias, blocks.5.norm2.weight, blocks.5.norm2.bias, blocks.5.mlp.fc1.weight, blocks.5.mlp.fc1.bias, blocks.5.mlp.fc2.weight, blocks.5.mlp.fc2.bias, norm.weight, norm.bias

load checkpoint from local path: /home/featurize/Results/Size_5_Experiment_2_Fold_1_Setting_1/best_mIoU_epoch_10.pth
[                                                  ] 0/55, elapsed: 0s, ETA:[                                                  ] 1/55, 0.4 task/s, elapsed: 2s, ETA:   121s[>                                                 ] 2/55, 0.9 task/s, elapsed: 2s, ETA:    61s[>>                                                ] 3/55, 1.3 task/s, elapsed: 2s, ETA:    41s[>>>                                               ] 4/55, 1.6 task/s, elapsed: 2s, ETA:    31s[>>>>                                              ] 5/55, 2.0 task/s, elapsed: 2s, ETA:    25s[>>>>>                                             ] 6/55, 2.4 task/s, elapsed: 3s, ETA:    21s[>>>>>>                                            ] 7/55, 2.7 task/s, elapsed: 3s, ETA:    18s[>>>>>>>                                           ] 8/55, 3.0 task/s, elapsed: 3s, ETA:    15s[>>>>>>>>                                          ] 9/55, 3.4 task/s, elapsed: 3s, ETA:    14s[>>>>>>>>>                                         ] 10/55, 3.6 task/s, elapsed: 3s, ETA:    12s[>>>>>>>>>>                                        ] 11/55, 3.9 task/s, elapsed: 3s, ETA:    11s[>>>>>>>>>>                                        ] 12/55, 4.2 task/s, elapsed: 3s, ETA:    10s[>>>>>>>>>>>                                       ] 13/55, 4.5 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>>>>>                                      ] 14/55, 4.7 task/s, elapsed: 3s, ETA:     9s[>>>>>>>>>>>>>                                     ] 15/55, 4.9 task/s, elapsed: 3s, ETA:     8s[>>>>>>>>>>>>>>                                    ] 16/55, 5.2 task/s, elapsed: 3s, ETA:     8s[>>>>>>>>>>>>>>>                                   ] 17/55, 5.4 task/s, elapsed: 3s, ETA:     7s[>>>>>>>>>>>>>>>>                                  ] 18/55, 5.6 task/s, elapsed: 3s, ETA:     7s[>>>>>>>>>>>>>>>>>                                 ] 19/55, 5.9 task/s, elapsed: 3s, ETA:     6s[>>>>>>>>>>>>>>>>>>                                ] 20/55, 6.1 task/s, elapsed: 3s, ETA:     6s[>>>>>>>>>>>>>>>>>>>                               ] 21/55, 6.3 task/s, elapsed: 3s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>                              ] 22/55, 6.5 task/s, elapsed: 3s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>                              ] 23/55, 6.7 task/s, elapsed: 3s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>                             ] 24/55, 6.9 task/s, elapsed: 3s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>                            ] 25/55, 7.1 task/s, elapsed: 4s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>                           ] 26/55, 7.3 task/s, elapsed: 4s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>                          ] 27/55, 7.5 task/s, elapsed: 4s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>                         ] 28/55, 7.6 task/s, elapsed: 4s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>                        ] 29/55, 7.8 task/s, elapsed: 4s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>                       ] 30/55, 8.0 task/s, elapsed: 4s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>                      ] 31/55, 8.2 task/s, elapsed: 4s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                     ] 32/55, 8.3 task/s, elapsed: 4s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                    ] 33/55, 8.5 task/s, elapsed: 4s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                    ] 34/55, 8.6 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                   ] 35/55, 8.8 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                  ] 36/55, 8.8 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                 ] 37/55, 9.0 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                ] 38/55, 9.2 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>               ] 39/55, 9.3 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>              ] 40/55, 9.4 task/s, elapsed: 4s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>             ] 41/55, 9.5 task/s, elapsed: 4s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>            ] 42/55, 9.6 task/s, elapsed: 4s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>           ] 43/55, 9.8 task/s, elapsed: 4s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>          ] 44/55, 9.9 task/s, elapsed: 4s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>          ] 45/55, 10.0 task/s, elapsed: 4s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>         ] 46/55, 10.1 task/s, elapsed: 5s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>        ] 47/55, 10.3 task/s, elapsed: 5s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 48/55, 10.4 task/s, elapsed: 5s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 49/55, 10.5 task/s, elapsed: 5s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 50/55, 10.6 task/s, elapsed: 5s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 51/55, 10.7 task/s, elapsed: 5s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 52/55, 10.8 task/s, elapsed: 5s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 53/55, 11.0 task/s, elapsed: 5s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 54/55, 11.1 task/s, elapsed: 5s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 11.2 task/s, elapsed: 5s, ETA:     0sper class results:

+-----------+--------+-----------+--------+
|   Class   | Fscore | Precision | Recall |
+-----------+--------+-----------+--------+
|   Wheat   |  4.29  |   47.87   |  2.24  |
|   Maize   |  2.61  |   10.25   |  1.5   |
|  Sorghum  |  2.35  |    1.43   |  6.63  |
|   Barley  |  2.47  |   17.74   |  1.33  |
|    Rye    |  0.1   |    0.06   |  0.31  |
|    Oats   |  7.86  |    4.3    |  45.9  |
|   Grapes  |  0.78  |    0.52   |  1.53  |
|  Rapeseed |  8.59  |   12.06   |  6.68  |
| Sunflower |  9.58  |    5.95   | 24.59  |
|  Potatoes |  4.46  |    3.05   |  8.31  |
|    Peas   |  3.62  |    2.46   |  6.86  |
+-----------+--------+-----------+--------+
Summary:

+------+---------+------------+---------+
| aAcc | mFscore | mPrecision | mRecall |
+------+---------+------------+---------+
| 5.97 |   4.25  |    9.61    |   9.63  |
+------+---------+------------+---------+
Testing finished successfully.
