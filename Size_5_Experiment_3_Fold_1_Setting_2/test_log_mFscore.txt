Testing command is /home/featurize/work/uc/bin/python /home/featurize/work/uc/lib/python3.9/site-packages/mmseg/.mim/tools/test.py /home/featurize/work/hls-foundation-os/configs/size_5/experiment_3/size_5_experiment_3_fold_1_setting_2.py /home/featurize/Results/Size_5_Experiment_3_Fold_1_Setting_2/best_mIoU_epoch_10.pth --launcher none --eval mFscore. 
load from /home/featurize/work/hls-foundation-os/Current_Pretrained_Prithvi_Weights/Prithvi_EO_V1_100M.pt
load checkpoint from local path: /home/featurize/work/hls-foundation-os/Current_Pretrained_Prithvi_Weights/Prithvi_EO_V1_100M.pt
The model and loaded state dict do not match exactly

unexpected key in source state_dict: encoder.cls_token, encoder.pos_embed, decoder.mask_token, decoder.decoder_pos_embed, encoder.patch_embed.proj.weight, encoder.patch_embed.proj.bias, encoder.blocks.0.norm1.weight, encoder.blocks.0.norm1.bias, encoder.blocks.0.attn.qkv.weight, encoder.blocks.0.attn.qkv.bias, encoder.blocks.0.attn.proj.weight, encoder.blocks.0.attn.proj.bias, encoder.blocks.0.norm2.weight, encoder.blocks.0.norm2.bias, encoder.blocks.0.mlp.fc1.weight, encoder.blocks.0.mlp.fc1.bias, encoder.blocks.0.mlp.fc2.weight, encoder.blocks.0.mlp.fc2.bias, encoder.blocks.1.norm1.weight, encoder.blocks.1.norm1.bias, encoder.blocks.1.attn.qkv.weight, encoder.blocks.1.attn.qkv.bias, encoder.blocks.1.attn.proj.weight, encoder.blocks.1.attn.proj.bias, encoder.blocks.1.norm2.weight, encoder.blocks.1.norm2.bias, encoder.blocks.1.mlp.fc1.weight, encoder.blocks.1.mlp.fc1.bias, encoder.blocks.1.mlp.fc2.weight, encoder.blocks.1.mlp.fc2.bias, encoder.blocks.2.norm1.weight, encoder.blocks.2.norm1.bias, encoder.blocks.2.attn.qkv.weight, encoder.blocks.2.attn.qkv.bias, encoder.blocks.2.attn.proj.weight, encoder.blocks.2.attn.proj.bias, encoder.blocks.2.norm2.weight, encoder.blocks.2.norm2.bias, encoder.blocks.2.mlp.fc1.weight, encoder.blocks.2.mlp.fc1.bias, encoder.blocks.2.mlp.fc2.weight, encoder.blocks.2.mlp.fc2.bias, encoder.blocks.3.norm1.weight, encoder.blocks.3.norm1.bias, encoder.blocks.3.attn.qkv.weight, encoder.blocks.3.attn.qkv.bias, encoder.blocks.3.attn.proj.weight, encoder.blocks.3.attn.proj.bias, encoder.blocks.3.norm2.weight, encoder.blocks.3.norm2.bias, encoder.blocks.3.mlp.fc1.weight, encoder.blocks.3.mlp.fc1.bias, encoder.blocks.3.mlp.fc2.weight, encoder.blocks.3.mlp.fc2.bias, encoder.blocks.4.norm1.weight, encoder.blocks.4.norm1.bias, encoder.blocks.4.attn.qkv.weight, encoder.blocks.4.attn.qkv.bias, encoder.blocks.4.attn.proj.weight, encoder.blocks.4.attn.proj.bias, encoder.blocks.4.norm2.weight, encoder.blocks.4.norm2.bias, encoder.blocks.4.mlp.fc1.weight, encoder.blocks.4.mlp.fc1.bias, encoder.blocks.4.mlp.fc2.weight, encoder.blocks.4.mlp.fc2.bias, encoder.blocks.5.norm1.weight, encoder.blocks.5.norm1.bias, encoder.blocks.5.attn.qkv.weight, encoder.blocks.5.attn.qkv.bias, encoder.blocks.5.attn.proj.weight, encoder.blocks.5.attn.proj.bias, encoder.blocks.5.norm2.weight, encoder.blocks.5.norm2.bias, encoder.blocks.5.mlp.fc1.weight, encoder.blocks.5.mlp.fc1.bias, encoder.blocks.5.mlp.fc2.weight, encoder.blocks.5.mlp.fc2.bias, encoder.blocks.6.norm1.weight, encoder.blocks.6.norm1.bias, encoder.blocks.6.attn.qkv.weight, encoder.blocks.6.attn.qkv.bias, encoder.blocks.6.attn.proj.weight, encoder.blocks.6.attn.proj.bias, encoder.blocks.6.norm2.weight, encoder.blocks.6.norm2.bias, encoder.blocks.6.mlp.fc1.weight, encoder.blocks.6.mlp.fc1.bias, encoder.blocks.6.mlp.fc2.weight, encoder.blocks.6.mlp.fc2.bias, encoder.blocks.7.norm1.weight, encoder.blocks.7.norm1.bias, encoder.blocks.7.attn.qkv.weight, encoder.blocks.7.attn.qkv.bias, encoder.blocks.7.attn.proj.weight, encoder.blocks.7.attn.proj.bias, encoder.blocks.7.norm2.weight, encoder.blocks.7.norm2.bias, encoder.blocks.7.mlp.fc1.weight, encoder.blocks.7.mlp.fc1.bias, encoder.blocks.7.mlp.fc2.weight, encoder.blocks.7.mlp.fc2.bias, encoder.blocks.8.norm1.weight, encoder.blocks.8.norm1.bias, encoder.blocks.8.attn.qkv.weight, encoder.blocks.8.attn.qkv.bias, encoder.blocks.8.attn.proj.weight, encoder.blocks.8.attn.proj.bias, encoder.blocks.8.norm2.weight, encoder.blocks.8.norm2.bias, encoder.blocks.8.mlp.fc1.weight, encoder.blocks.8.mlp.fc1.bias, encoder.blocks.8.mlp.fc2.weight, encoder.blocks.8.mlp.fc2.bias, encoder.blocks.9.norm1.weight, encoder.blocks.9.norm1.bias, encoder.blocks.9.attn.qkv.weight, encoder.blocks.9.attn.qkv.bias, encoder.blocks.9.attn.proj.weight, encoder.blocks.9.attn.proj.bias, encoder.blocks.9.norm2.weight, encoder.blocks.9.norm2.bias, encoder.blocks.9.mlp.fc1.weight, encoder.blocks.9.mlp.fc1.bias, encoder.blocks.9.mlp.fc2.weight, encoder.blocks.9.mlp.fc2.bias, encoder.blocks.10.norm1.weight, encoder.blocks.10.norm1.bias, encoder.blocks.10.attn.qkv.weight, encoder.blocks.10.attn.qkv.bias, encoder.blocks.10.attn.proj.weight, encoder.blocks.10.attn.proj.bias, encoder.blocks.10.norm2.weight, encoder.blocks.10.norm2.bias, encoder.blocks.10.mlp.fc1.weight, encoder.blocks.10.mlp.fc1.bias, encoder.blocks.10.mlp.fc2.weight, encoder.blocks.10.mlp.fc2.bias, encoder.blocks.11.norm1.weight, encoder.blocks.11.norm1.bias, encoder.blocks.11.attn.qkv.weight, encoder.blocks.11.attn.qkv.bias, encoder.blocks.11.attn.proj.weight, encoder.blocks.11.attn.proj.bias, encoder.blocks.11.norm2.weight, encoder.blocks.11.norm2.bias, encoder.blocks.11.mlp.fc1.weight, encoder.blocks.11.mlp.fc1.bias, encoder.blocks.11.mlp.fc2.weight, encoder.blocks.11.mlp.fc2.bias, encoder.norm.weight, encoder.norm.bias, decoder.decoder_embed.weight, decoder.decoder_embed.bias, decoder.decoder_blocks.0.norm1.weight, decoder.decoder_blocks.0.norm1.bias, decoder.decoder_blocks.0.attn.qkv.weight, decoder.decoder_blocks.0.attn.qkv.bias, decoder.decoder_blocks.0.attn.proj.weight, decoder.decoder_blocks.0.attn.proj.bias, decoder.decoder_blocks.0.norm2.weight, decoder.decoder_blocks.0.norm2.bias, decoder.decoder_blocks.0.mlp.fc1.weight, decoder.decoder_blocks.0.mlp.fc1.bias, decoder.decoder_blocks.0.mlp.fc2.weight, decoder.decoder_blocks.0.mlp.fc2.bias, decoder.decoder_blocks.1.norm1.weight, decoder.decoder_blocks.1.norm1.bias, decoder.decoder_blocks.1.attn.qkv.weight, decoder.decoder_blocks.1.attn.qkv.bias, decoder.decoder_blocks.1.attn.proj.weight, decoder.decoder_blocks.1.attn.proj.bias, decoder.decoder_blocks.1.norm2.weight, decoder.decoder_blocks.1.norm2.bias, decoder.decoder_blocks.1.mlp.fc1.weight, decoder.decoder_blocks.1.mlp.fc1.bias, decoder.decoder_blocks.1.mlp.fc2.weight, decoder.decoder_blocks.1.mlp.fc2.bias, decoder.decoder_blocks.2.norm1.weight, decoder.decoder_blocks.2.norm1.bias, decoder.decoder_blocks.2.attn.qkv.weight, decoder.decoder_blocks.2.attn.qkv.bias, decoder.decoder_blocks.2.attn.proj.weight, decoder.decoder_blocks.2.attn.proj.bias, decoder.decoder_blocks.2.norm2.weight, decoder.decoder_blocks.2.norm2.bias, decoder.decoder_blocks.2.mlp.fc1.weight, decoder.decoder_blocks.2.mlp.fc1.bias, decoder.decoder_blocks.2.mlp.fc2.weight, decoder.decoder_blocks.2.mlp.fc2.bias, decoder.decoder_blocks.3.norm1.weight, decoder.decoder_blocks.3.norm1.bias, decoder.decoder_blocks.3.attn.qkv.weight, decoder.decoder_blocks.3.attn.qkv.bias, decoder.decoder_blocks.3.attn.proj.weight, decoder.decoder_blocks.3.attn.proj.bias, decoder.decoder_blocks.3.norm2.weight, decoder.decoder_blocks.3.norm2.bias, decoder.decoder_blocks.3.mlp.fc1.weight, decoder.decoder_blocks.3.mlp.fc1.bias, decoder.decoder_blocks.3.mlp.fc2.weight, decoder.decoder_blocks.3.mlp.fc2.bias, decoder.decoder_blocks.4.norm1.weight, decoder.decoder_blocks.4.norm1.bias, decoder.decoder_blocks.4.attn.qkv.weight, decoder.decoder_blocks.4.attn.qkv.bias, decoder.decoder_blocks.4.attn.proj.weight, decoder.decoder_blocks.4.attn.proj.bias, decoder.decoder_blocks.4.norm2.weight, decoder.decoder_blocks.4.norm2.bias, decoder.decoder_blocks.4.mlp.fc1.weight, decoder.decoder_blocks.4.mlp.fc1.bias, decoder.decoder_blocks.4.mlp.fc2.weight, decoder.decoder_blocks.4.mlp.fc2.bias, decoder.decoder_blocks.5.norm1.weight, decoder.decoder_blocks.5.norm1.bias, decoder.decoder_blocks.5.attn.qkv.weight, decoder.decoder_blocks.5.attn.qkv.bias, decoder.decoder_blocks.5.attn.proj.weight, decoder.decoder_blocks.5.attn.proj.bias, decoder.decoder_blocks.5.norm2.weight, decoder.decoder_blocks.5.norm2.bias, decoder.decoder_blocks.5.mlp.fc1.weight, decoder.decoder_blocks.5.mlp.fc1.bias, decoder.decoder_blocks.5.mlp.fc2.weight, decoder.decoder_blocks.5.mlp.fc2.bias, decoder.decoder_blocks.6.norm1.weight, decoder.decoder_blocks.6.norm1.bias, decoder.decoder_blocks.6.attn.qkv.weight, decoder.decoder_blocks.6.attn.qkv.bias, decoder.decoder_blocks.6.attn.proj.weight, decoder.decoder_blocks.6.attn.proj.bias, decoder.decoder_blocks.6.norm2.weight, decoder.decoder_blocks.6.norm2.bias, decoder.decoder_blocks.6.mlp.fc1.weight, decoder.decoder_blocks.6.mlp.fc1.bias, decoder.decoder_blocks.6.mlp.fc2.weight, decoder.decoder_blocks.6.mlp.fc2.bias, decoder.decoder_blocks.7.norm1.weight, decoder.decoder_blocks.7.norm1.bias, decoder.decoder_blocks.7.attn.qkv.weight, decoder.decoder_blocks.7.attn.qkv.bias, decoder.decoder_blocks.7.attn.proj.weight, decoder.decoder_blocks.7.attn.proj.bias, decoder.decoder_blocks.7.norm2.weight, decoder.decoder_blocks.7.norm2.bias, decoder.decoder_blocks.7.mlp.fc1.weight, decoder.decoder_blocks.7.mlp.fc1.bias, decoder.decoder_blocks.7.mlp.fc2.weight, decoder.decoder_blocks.7.mlp.fc2.bias, decoder.decoder_norm.weight, decoder.decoder_norm.bias, decoder.decoder_pred.weight, decoder.decoder_pred.bias

missing keys in source state_dict: cls_token, pos_embed, patch_embed.proj.weight, patch_embed.proj.bias, blocks.0.norm1.weight, blocks.0.norm1.bias, blocks.0.attn.qkv.weight, blocks.0.attn.qkv.bias, blocks.0.attn.proj.weight, blocks.0.attn.proj.bias, blocks.0.norm2.weight, blocks.0.norm2.bias, blocks.0.mlp.fc1.weight, blocks.0.mlp.fc1.bias, blocks.0.mlp.fc2.weight, blocks.0.mlp.fc2.bias, blocks.1.norm1.weight, blocks.1.norm1.bias, blocks.1.attn.qkv.weight, blocks.1.attn.qkv.bias, blocks.1.attn.proj.weight, blocks.1.attn.proj.bias, blocks.1.norm2.weight, blocks.1.norm2.bias, blocks.1.mlp.fc1.weight, blocks.1.mlp.fc1.bias, blocks.1.mlp.fc2.weight, blocks.1.mlp.fc2.bias, blocks.2.norm1.weight, blocks.2.norm1.bias, blocks.2.attn.qkv.weight, blocks.2.attn.qkv.bias, blocks.2.attn.proj.weight, blocks.2.attn.proj.bias, blocks.2.norm2.weight, blocks.2.norm2.bias, blocks.2.mlp.fc1.weight, blocks.2.mlp.fc1.bias, blocks.2.mlp.fc2.weight, blocks.2.mlp.fc2.bias, blocks.3.norm1.weight, blocks.3.norm1.bias, blocks.3.attn.qkv.weight, blocks.3.attn.qkv.bias, blocks.3.attn.proj.weight, blocks.3.attn.proj.bias, blocks.3.norm2.weight, blocks.3.norm2.bias, blocks.3.mlp.fc1.weight, blocks.3.mlp.fc1.bias, blocks.3.mlp.fc2.weight, blocks.3.mlp.fc2.bias, blocks.4.norm1.weight, blocks.4.norm1.bias, blocks.4.attn.qkv.weight, blocks.4.attn.qkv.bias, blocks.4.attn.proj.weight, blocks.4.attn.proj.bias, blocks.4.norm2.weight, blocks.4.norm2.bias, blocks.4.mlp.fc1.weight, blocks.4.mlp.fc1.bias, blocks.4.mlp.fc2.weight, blocks.4.mlp.fc2.bias, blocks.5.norm1.weight, blocks.5.norm1.bias, blocks.5.attn.qkv.weight, blocks.5.attn.qkv.bias, blocks.5.attn.proj.weight, blocks.5.attn.proj.bias, blocks.5.norm2.weight, blocks.5.norm2.bias, blocks.5.mlp.fc1.weight, blocks.5.mlp.fc1.bias, blocks.5.mlp.fc2.weight, blocks.5.mlp.fc2.bias, norm.weight, norm.bias

load checkpoint from local path: /home/featurize/Results/Size_5_Experiment_3_Fold_1_Setting_2/best_mIoU_epoch_10.pth
[                                                  ] 0/67, elapsed: 0s, ETA:[                                                  ] 1/67, 0.3 task/s, elapsed: 3s, ETA:   191s[>                                                 ] 2/67, 0.7 task/s, elapsed: 3s, ETA:    96s[>>                                                ] 3/67, 1.0 task/s, elapsed: 3s, ETA:    64s[>>                                                ] 4/67, 1.3 task/s, elapsed: 3s, ETA:    48s[>>>                                               ] 5/67, 1.6 task/s, elapsed: 3s, ETA:    39s[>>>>                                              ] 6/67, 1.9 task/s, elapsed: 3s, ETA:    33s[>>>>>                                             ] 7/67, 2.1 task/s, elapsed: 3s, ETA:    28s[>>>>>                                             ] 8/67, 2.4 task/s, elapsed: 3s, ETA:    25s[>>>>>>                                            ] 9/67, 2.6 task/s, elapsed: 3s, ETA:    22s[>>>>>>>                                           ] 10/67, 2.9 task/s, elapsed: 4s, ETA:    20s[>>>>>>>>                                          ] 11/67, 3.1 task/s, elapsed: 4s, ETA:    18s[>>>>>>>>                                          ] 12/67, 3.3 task/s, elapsed: 4s, ETA:    17s[>>>>>>>>>                                         ] 13/67, 3.5 task/s, elapsed: 4s, ETA:    15s[>>>>>>>>>>                                        ] 14/67, 3.7 task/s, elapsed: 4s, ETA:    14s[>>>>>>>>>>>                                       ] 15/67, 3.9 task/s, elapsed: 4s, ETA:    13s[>>>>>>>>>>>                                       ] 16/67, 4.1 task/s, elapsed: 4s, ETA:    12s[>>>>>>>>>>>>                                      ] 17/67, 4.3 task/s, elapsed: 4s, ETA:    12s[>>>>>>>>>>>>>                                     ] 18/67, 4.5 task/s, elapsed: 4s, ETA:    11s[>>>>>>>>>>>>>>                                    ] 19/67, 4.7 task/s, elapsed: 4s, ETA:    10s[>>>>>>>>>>>>>>                                    ] 20/67, 4.9 task/s, elapsed: 4s, ETA:    10s[>>>>>>>>>>>>>>>                                   ] 21/67, 5.0 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>>>>>>>                                  ] 22/67, 5.2 task/s, elapsed: 4s, ETA:     9s[>>>>>>>>>>>>>>>>>                                 ] 23/67, 5.3 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>>>>>>>                                 ] 24/67, 5.5 task/s, elapsed: 4s, ETA:     8s[>>>>>>>>>>>>>>>>>>                                ] 25/67, 5.6 task/s, elapsed: 4s, ETA:     7s[>>>>>>>>>>>>>>>>>>>                               ] 26/67, 5.8 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>                              ] 27/67, 5.9 task/s, elapsed: 5s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>                              ] 28/67, 6.0 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>                             ] 29/67, 6.2 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>                            ] 30/67, 6.3 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>                           ] 31/67, 6.4 task/s, elapsed: 5s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>                           ] 32/67, 6.5 task/s, elapsed: 5s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>                          ] 33/67, 6.7 task/s, elapsed: 5s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>                         ] 34/67, 6.8 task/s, elapsed: 5s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>                        ] 35/67, 6.9 task/s, elapsed: 5s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>                        ] 36/67, 7.0 task/s, elapsed: 5s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>                       ] 37/67, 7.1 task/s, elapsed: 5s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>                      ] 38/67, 7.2 task/s, elapsed: 5s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                     ] 39/67, 7.3 task/s, elapsed: 5s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                     ] 40/67, 7.4 task/s, elapsed: 5s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                    ] 41/67, 7.5 task/s, elapsed: 5s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                   ] 42/67, 7.6 task/s, elapsed: 6s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                  ] 43/67, 7.7 task/s, elapsed: 6s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                  ] 44/67, 7.8 task/s, elapsed: 6s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                 ] 45/67, 7.9 task/s, elapsed: 6s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>                ] 46/67, 8.0 task/s, elapsed: 6s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>               ] 47/67, 8.1 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>               ] 48/67, 8.2 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>              ] 49/67, 8.3 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>             ] 50/67, 8.3 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>            ] 51/67, 8.4 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>            ] 52/67, 8.5 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>           ] 53/67, 8.6 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>          ] 54/67, 8.6 task/s, elapsed: 6s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>         ] 55/67, 8.7 task/s, elapsed: 6s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>         ] 56/67, 8.8 task/s, elapsed: 6s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>        ] 57/67, 8.9 task/s, elapsed: 6s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>       ] 58/67, 8.9 task/s, elapsed: 7s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 59/67, 9.0 task/s, elapsed: 7s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 60/67, 9.1 task/s, elapsed: 7s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 61/67, 9.1 task/s, elapsed: 7s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 62/67, 9.2 task/s, elapsed: 7s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 63/67, 9.3 task/s, elapsed: 7s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 64/67, 9.4 task/s, elapsed: 7s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 65/67, 9.5 task/s, elapsed: 7s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 66/67, 9.6 task/s, elapsed: 7s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 67/67, 9.6 task/s, elapsed: 7s, ETA:     0sper class results:

+-----------+--------+-----------+--------+
|   Class   | Fscore | Precision | Recall |
+-----------+--------+-----------+--------+
|   Wheat   |  0.52  |    0.34   |  1.17  |
|   Maize   | 17.33  |   16.94   | 17.73  |
|  Sorghum  |  0.88  |    0.46   |  8.8   |
|   Barley  |  0.56  |    71.1   |  0.28  |
|    Rye    |  0.95  |    0.49   | 14.08  |
|    Oats   |  2.77  |   10.95   |  1.58  |
|   Grapes  | 18.48  |   14.25   | 26.27  |
|  Rapeseed |  4.03  |    5.62   |  3.15  |
| Sunflower |  1.73  |    1.13   |  3.72  |
|  Potatoes |  0.88  |    0.45   | 14.81  |
|    Peas   |  5.43  |    3.37   | 13.93  |
+-----------+--------+-----------+--------+
Summary:

+------+---------+------------+---------+
| aAcc | mFscore | mPrecision | mRecall |
+------+---------+------------+---------+
| 6.85 |   4.87  |   11.37    |   9.59  |
+------+---------+------------+---------+
Testing finished successfully.
